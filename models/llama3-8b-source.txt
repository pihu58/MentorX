### Llama 3 8B (Semantic Pipeline LLM)

**Function in MentorX:**
This model serves as the core "Pedagogical Expert" evaluator. It processes the timestamped transcripts generated by Whisper, applies a custom prompt, and outputs deterministic JSON scores (0-10) for content metrics like clarity, correctness, structure, and concept coverage.

**Source and Access Method:**
* **Model:** Llama 3 8B Instruct (Meta)
* **Provider:** Groq LPU API
* **Reasoning for External API:** The model inference was offloaded to the Groq LPU due to low VRAM constraints on local/cloud instances, which made local Llama-3 inference infeasible. This strategy reduced the Docker footprint by 4GB.
* **Access in Code:** The backend service (FastAPI) makes synchronous or asynchronous calls to the Groq API endpoint, passing the transcribed text and the validated scoring schema.

**Official Model Link:** [https://www.llama.com/models/llama-3/]